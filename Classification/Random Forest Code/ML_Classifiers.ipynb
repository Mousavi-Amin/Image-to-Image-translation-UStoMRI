{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1342693d-1c68-4dc2-ac79-374d29d45eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "##############  Variables ########################\n",
    "PCA_NoF=10\n",
    "\n",
    "\n",
    "# Read data from Excel files, US. MRI, Pix2Pix2D, CycleGAN3D, CycleGAN2D, AutoEncoder3D, UNet3D\n",
    "Output = pd.read_excel('ADD OUTCOME FILE')\n",
    "Input_Train = pd.read_excel('ADD TRAING DATASET')\n",
    "Input_Val = pd.read_excel('ADD VALIDATION DATASET')\n",
    "Input_Test= pd.read_excel('ADD TESTING DATASET')\n",
    "#print(Output)\n",
    "######Size datasets ################\n",
    "trnnum_rows = len(Input_Train)\n",
    "valnum_rows = len(Input_Val)\n",
    "tstnum_rows = len(Input_Test)\n",
    "#print(\"Shape of Train dataset:\", Input_Train.shape)\n",
    "#print(\"Shape of Validation dataset:\", Input_Val.shape)\n",
    "#print(\"Shape of Test dataset:\", Input_Test.shape)\n",
    "#print(Input_Train)\n",
    "#print(Input_Val)\n",
    "#print(Input_Test)\n",
    "\n",
    "\n",
    "####Split Patient ID ################\n",
    "PItrn =Input_Train.iloc[:, :1]\n",
    "PIval =Input_Val.iloc[:, :1] \n",
    "PItst =Input_Test.iloc[:, :1] \n",
    "#print(\"Shape of IDtrn dataset:\", PItrn.shape)\n",
    "#print(\"Shape of IDval dataset:\", PIval.shape)\n",
    "#print(\"Shape of IDtst dataset:\", PItst.shape)\n",
    "#print(PItrn)\n",
    "#print(PIval)\n",
    "#print(PItst)\n",
    "\n",
    "\n",
    "########### Concatenate data vertically #############\n",
    "Total_data = pd.concat([Input_Train, Input_Val, Input_Test], ignore_index=True)\n",
    "#print(\"Shape of Totaldataset:\", Total_data.shape)\n",
    "#print(Total_data)\n",
    "\n",
    "############3 It's a good practice to standardize the data before PCA #####################3\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(Total_data.iloc[:, 3:])\n",
    "\n",
    "# Create PCA instance: PCA for 50 components\n",
    "pca = PCA(n_components=PCA_NoF)\n",
    "\n",
    "# Fit on data\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Transform the data\n",
    "X_pca = pca.transform(X_scaled)\n",
    "#print(\"Shape of PCA total dataset:\", X_pca.shape)\n",
    "#print(X_pca)\n",
    "# Extract PCA results for Train, Validation, and Test sets\n",
    "\n",
    "\n",
    "PCAtrn = pd.DataFrame(X_pca[:trnnum_rows, :])  # Rows from 0 to trnnum_rows-1 for training\n",
    "PCAval = pd.DataFrame(X_pca[trnnum_rows:trnnum_rows+valnum_rows, :])  # Rows from trnnum_rows to trnnum_rows+valnum_rows-1 for validation\n",
    "PCAtst = pd.DataFrame(X_pca[trnnum_rows+valnum_rows:, :])  # Rows from trnnum_rows+valnum_rows to the end for testing\n",
    "#print(\"Shape of PCA Train dataset:\", PCAtrain.shape)\n",
    "#print(\"Shape of PCA Validation dataset:\", PCAval.shape)\n",
    "#print(\"Shape of PCA Test dataset:\", PCAtst.shape)\n",
    "#print(PCAtrain)\n",
    "#print(PCAval)\n",
    "#print(PCAtst)\n",
    "\n",
    "\n",
    "\n",
    "#################Concatinate Patiant ID with PCA train, PCA val and PCA test ###############3\n",
    "\n",
    "concatenated_trn = pd.concat([PItrn, PCAtrn], axis=1)\n",
    "concatenated_val = pd.concat([PIval, PCAval], axis=1)\n",
    "concatenated_tst = pd.concat([PItst, PCAtst], axis=1)\n",
    "#print(\"Shape of concatinated trndataset:\", concatenated_trn.shape)\n",
    "#print(\"Shape of concatinated valdataset:\", concatenated_val.shape)\n",
    "#print(\"Shape of concatinated tstdataset:\", concatenated_tst.shape)\n",
    "#print(concatenated_trn)\n",
    "#print(concatenated_val)\n",
    "#print(concatenated_tst)\n",
    "\n",
    "\n",
    "################Select related labels##########################33\n",
    "###########For training #####################\n",
    "numeric_label = {'low': 0, 'high': 1}\n",
    "for patient in Output['PatientID']:\n",
    "         for train_patient in concatenated_trn['PatientID']:\n",
    "    \n",
    "            if train_patient[:4] == patient[-4:]:\n",
    "                grade = Output.loc[Output['PatientID'] == patient, 'Label'].squeeze()\n",
    "                #print(grade)\n",
    "                concatenated_trn.loc[concatenated_trn['PatientID'] == train_patient, 'Label'] = grade\n",
    "                concatenated_trn.loc[concatenated_trn['PatientID'] == train_patient, 'Label_Num'] = int(numeric_label[grade])\n",
    "#print(concatenated_trn)\n",
    "#print(\"Shape of concatinated trndataset:\", concatenated_trn.shape)\n",
    "#print(concatenated_trn)\n",
    "\n",
    "########### For Val #####################\n",
    "for val_patient in concatenated_val['PatientID']:\n",
    "        for patient in Output['PatientID']:\n",
    "            if val_patient[:4] == patient[-4:]:\n",
    "                grade = Output.loc[Output['PatientID'] == patient, 'Label'].squeeze()\n",
    "                concatenated_val.loc[concatenated_val['PatientID'] == val_patient, 'Label'] = grade\n",
    "                concatenated_val.loc[concatenated_val['PatientID'] == val_patient, 'Label_Num'] = int(numeric_label[grade])\n",
    "#print(\"Shape of concatinated valdataset:\", concatenated_val.shape)\n",
    "\n",
    "########### For Test#####################\n",
    "for tst_patient in concatenated_tst['PatientID']:\n",
    "        for patient in Output['PatientID']:\n",
    "            if tst_patient[:4] == patient[-4:]:\n",
    "                grade = Output.loc[Output['PatientID'] == patient, 'Label'].squeeze()\n",
    "                concatenated_tst.loc[concatenated_tst['PatientID'] == tst_patient, 'Label'] = grade\n",
    "                concatenated_tst.loc[concatenated_tst['PatientID'] == tst_patient, 'Label_Num'] = int(numeric_label[grade])\n",
    "#print(\"Shape of concatinaed tstdataset:\", concatenated_tst.shape)\n",
    "#print(concatenated_tst)\n",
    "\n",
    "############Clean NaN################\n",
    "clean_Trn = concatenated_trn.dropna(subset='Label_Num')\n",
    "clean_Val = concatenated_val.dropna(subset='Label_Num')\n",
    "clean_Tst= concatenated_tst.dropna(subset='Label_Num')\n",
    "\n",
    "#print(\"Shape of concatinated tstdataset:\", clean_Trn.shape)\n",
    "#print(\"Shape of concatinated tstdataset:\", clean_Val.shape)\n",
    "#print(\"Shape of concatinated tstdataset:\", clean_Tst.shape)\n",
    "#print(clean_Trn)\n",
    "#print(clean_Val)\n",
    "#print(clean_Tst)\n",
    "\n",
    "\n",
    "######################Classifiers##############################\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Train the classifier\n",
    "##### Split feature for predictor ###################3\n",
    "X_trn=clean_Trn.iloc[:, 1:-2]\n",
    "Y_trn=clean_Trn.iloc[:, -1:]\n",
    "X_val=clean_Val.iloc[:, 1:-2]\n",
    "Y_val=clean_Val.iloc[:, -1:]\n",
    "X_tst=clean_Tst.iloc[:, 1:-2]\n",
    "Y_tst=clean_Tst.iloc[:, -1:]\n",
    "\n",
    "Total_X_trn = pd.concat([X_trn, X_val], ignore_index=True)#### Concatinate X train and val\n",
    "Total_Y_trn = pd.concat([Y_trn, Y_val], ignore_index=True)#### Concatinate X train and val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "122ce615-fbac-4916-a659-e42d708db3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a98aad0-66e9-47fa-b35b-88e127492d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#print(\"Shape of concatinated tstdataset:\", Total_X_trn.shape)\n",
    "#print(\"Shape of concatinated tstdataset:\", Total_Y_trn.shape)\n",
    "#print(Total_X_trn)\n",
    "#print(Total_Y_trn)\n",
    "#print(\"Shape of concatinated tstdataset:\", X_tst.shape)\n",
    "#print(\"Shape of concatinated tstdataset:\", Y_tst.shape)\n",
    "#print(X_tst)\n",
    "#print(Y_tst)\n",
    "#print(concatenated_tst.iloc[:, -1:])\n",
    "# Initialize MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "#clf = RandomForestClassifier(n_estimators=50000, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=100,  # Number of trees in the forest\n",
    "                             criterion='gini',  # Splitting criterion (default is 'gini')\n",
    "                             max_depth=100,   # Maximum depth of the trees (default is None)\n",
    "                             min_samples_split=2,  # Minimum number of samples required to split an internal node\n",
    "                             min_samples_leaf=1,   # Minimum number of samples required to be at a leaf node\n",
    "                             max_features='auto',  # Number of features to consider for the best split\n",
    "                             bootstrap=True,  # Whether bootstrap samples are used when building trees\n",
    "                             random_state=11)  # Seed for random number generation\n",
    "clf.fit(Total_X_trn, Total_Y_trn)\n",
    "\n",
    "# Get predicted probabilities for the positive class\n",
    "y_probs = clf.predict_proba(X_tst)[:, 1]  # Use [:, 1] for positive class probabilities\n",
    "RFYpre = (y_probs >= 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "#print([Ypre,Y_tst])\n",
    "    \n",
    "# Calculate accuracy\n",
    "accuracyRF = accuracy_score(Y_tst, RFYpre)\n",
    "print(\"Accuracy:\", round(accuracyRF, 2))\n",
    "#print(Y_tst)\n",
    "#print(RFYpre)\n",
    "# Calculate AUC\n",
    "aucRF = roc_auc_score(Y_tst, RFYpre)\n",
    "print(\"AUC:\", round(aucRF, 2))\n",
    "\n",
    "#class_counts = Total_Y_trn['Label_Num'].value_counts()\n",
    "#print(class_counts)\n",
    "\n",
    "#class_counts = Y_tst['Label_Num'].value_counts()\n",
    "#print(class_counts)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3eab6-63a1-44d7-a5be-a9bc328cd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"RandF\")\n",
    "print(\"Accuracy:\", round(accuracyRF, 2))\n",
    "print(\"AUC:\", round(aucRF, 2))\n",
    "print(\"-----------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4451d-9712-4650-bde8-fd192ae2cf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
